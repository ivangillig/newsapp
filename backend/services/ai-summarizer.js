import OpenAI from 'openai'
import { logger } from '../utils/logger.js'
import NewsCache from '../models/NewsCache.js'
import { scrapeAllPortals, scrapeArticle } from './scraper.js'

// Lazy initialization - se crea cuando se usa, no al importar
let openai = null

function getOpenAI() {
  if (!openai) {
    openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    })
  }
  return openai
}

const SYSTEM_PROMPT = `Sos un analista de noticias experto argentino.
Te paso contenido crudo de portales de noticias. Tu tarea es generar un resumen ejecutivo.

REGLAS ESTRICTAS:

1. ESTRUCTURA: Primero una secci√≥n PRINCIPALES, luego si o si 9 categor√≠as:

   ## PRINCIPALES
   (Las 5 noticias m√°s importantes del d√≠a, sin importar categor√≠a)
   
   ## POL√çTICA
   ## ECONOM√çA  
   ## SOCIEDAD
   ## MUNDO
   ## DEPORTES
   ## TECNOLOG√çA
   ## ESPECT√ÅCULOS
   ## POLICIALES
   ## CLIMA

2. FORMATO: Us√° este formato exacto (INCLUIR URL debajo de cada noticia):
   ## NOMBRE_CATEGORIA
   - T√≠tulo de la noticia: Descripci√≥n breve y clara de la noticia.
   [URL_DE_LA_NOTICIA]
   - Otra noticia: Descripci√≥n de esta otra noticia.
   [URL_DE_LA_NOTICIA]

3. CONTENIDO:
   - PRINCIPALES: Exactamente 5 noticias (las m√°s relevantes del d√≠a)
   - Otras categor√≠as: M√°ximo 3 noticias cada una
   - Cada noticia tiene: T√≠tulo corto + dos puntos + descripci√≥n + URL en l√≠nea siguiente entre []
   - Frases directas, sin rodeos
   - Si no hay noticias de una categor√≠a, omitila (excepto PRINCIPALES)

4. PROHIBIDO:
   - NO uses emojis ni iconos
   - NO uses asteriscos ni formato markdown excepto ## para categor√≠as y [] para URLs
   - NO repitas noticias en m√°s de una categor√≠a (excepto PRINCIPALES)

5. TONO: Informal-profesional, como explic√°rselo a alguien inteligente con poco tiempo.

Devolv√© SOLO el resumen, sin introducciones ni despedidas.`

export async function summarizeContent(rawContent) {
  try {
    logger.info('ü§ñ Generating summary with OpenAI...')

    const response = await getOpenAI().chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: SYSTEM_PROMPT },
        { role: 'user', content: rawContent },
      ],
      temperature: 0.7,
      max_tokens: 2000,
    })

    const summary = response.choices[0].message.content

    logger.info(`‚úÖ Summary generated (${summary.length} characters)`)

    return summary
  } catch (error) {
    logger.error('Error generating summary:', error)
    throw error
  }
}

// Explain article in informal/casual tone
export async function explainArticle(title, content) {
  try {
    const EXPLAIN_PROMPT = `Sos un periodista argentino que explica noticias de forma clara y accesible para cualquier persona.

Tu objetivo es explicar la noticia de manera que cualquiera la entienda, sin perder profesionalismo.

TONO Y ESTILO:
- Profesional pero cercano (NO uses "che", "boludo" ni exceso de lunfardo)
- Manten√© neutralidad pol√≠tica absoluta
- Pod√©s usar palabras coloquiales como "guita", "quilombo" si ayudan a clarificar
- Explic√° conceptos t√©cnicos/pol√≠ticos de forma simple, con ejemplos concretos

FORMATO VISUAL (MUY IMPORTANTE):
- PROHIBIDO usar markdown: NO uses #, ##, ###, **, __, etc.
- Los t√≠tulos/subt√≠tulos se hacen SOLO con emojis + texto plano
- Ejemplo correcto: "üßâ ¬øQu√© dijo X, b√°sicamente?" o "üí∏ ¬øPor qu√© no juntaron reservas?"
- Us√° bullets con s√≠mbolos por ejemplo estos: üëâ, ‚Ä¢, ‚úÖ, ‚ùå (NO uses - o * para bullets)
- Frases cortas y directas
- L√≠neas en blanco entre secciones para respirar

ESTRUCTURA:
- Divid√≠ en bloques tem√°ticos con preguntas como subt√≠tulos
- Cada secci√≥n empieza con emoji + pregunta o t√≠tulo descriptivo
- Us√° bullets para listar puntos clave
- Cerr√° con un resumen corto de lo m√°s importante

CONTENIDO:
- Explic√° los hechos principales de forma clara
- Traduc√≠/aclar√° entre par√©ntesis lo que sea complejo
- Ejemplos concretos cuando ayude

Devolv√© SOLO la explicaci√≥n en texto plano con emojis, sin markdown.`

    const response = await getOpenAI().chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: EXPLAIN_PROMPT },
        {
          role: 'user',
          content: `T√≠tulo: ${title}\n\nContenido:\n${content.substring(
            0,
            3000
          )}`, // Limitar para evitar exceso de tokens
        },
      ],
      temperature: 0.8, // M√°s creativo para el tono informal
      max_tokens: 1000,
    })

    const explanation = response.choices[0].message.content
    return explanation
  } catch (error) {
    logger.error('Error explaining article:', error)
    return null // Si falla, no bloquear todo
  }
}

// Extract URLs from the summary markdown
function extractUrlsFromSummary(summary) {
  const urls = []
  // Search for [URL] in the markdown
  const urlRegex = /\[(https?:\/\/[^\]]+)\]/g
  let match
  while ((match = urlRegex.exec(summary)) !== null) {
    urls.push(match[1])
  }
  return [...new Set(urls)] // Deduplicate
}

// Check if the cache is recent (less than 30 minutes)
export async function isCacheRecent() {
  const cached = await NewsCache.findOne().sort({ createdAt: -1 })

  if (!cached) return false

  const cacheAge = Date.now() - new Date(cached.createdAt).getTime()
  const thirtyMinutes = 30 * 60 * 1000
  return cacheAge < thirtyMinutes
}

// Get the latest cached summary (for users)
export async function getSummary() {
  try {
    const cached = await NewsCache.findOne().sort({ createdAt: -1 })

    if (cached) {
      const cacheAge = Date.now() - new Date(cached.createdAt).getTime()
      const minutes = Math.floor(cacheAge / 60000)
      logger.info(`üì¶ Using cached summary (${minutes} min old)`)
      return cached.summary
    }

    // If no cache, generate one (only the first time)
    logger.info('‚ö†Ô∏è No cache found, generating first summary...')
    return await refreshSummary()
  } catch (error) {
    logger.error('Error getting summary:', error)
    throw new Error('No se pudo obtener resumen de noticias')
  }
}

// Refresh the cache (only for cron jobs)
export async function refreshSummary() {
  try {
    logger.info('üîÑ Refreshing news cache...')

    // Scrape fresh content
    const scrapedData = await scrapeAllPortals()

    // Collect all articles
    const allArticles = []
    scrapedData.forEach((portalData) => {
      if (!portalData.error && portalData.articles) {
        allArticles.push(...portalData.articles)
      }
    })

    if (allArticles.length === 0) {
      throw new Error('No articles scraped from portals')
    }

    logger.info(`üì∞ Collected ${allArticles.length} articles`)

    // Formatting articles for OpenAI (only include content if it exists)
    const combinedContent = allArticles
      .map((article) => {
        const parts = [`[${article.portal}] ${article.title}`]
        if (article.content) {
          parts.push(article.content)
        }
        parts.push(`URL: ${article.url}`)
        return parts.join('\n')
      })
      .join('\n\n---\n\n')

    // Generate summary with AI
    const summary = await summarizeContent(combinedContent)

    // Extract URLs from the generated summary
    const selectedUrls = extractUrlsFromSummary(summary)
    logger.info(`üîó Summary contains ${selectedUrls.length} article URLs`)

    // Scrape full content of selected articles
    const fullArticles = []
    if (selectedUrls.length > 0) {
      logger.info('üì• Fetching full content for selected articles...')
      const articlePromises = selectedUrls.map((url) => scrapeArticle(url))
      const scrapedArticles = await Promise.all(articlePromises)

      // Process each article and generate explanation IN PARALLEL
      logger.info(
        `ü§ñ Explaining ${scrapedArticles.length} articles in parallel...`
      )
      const explanationPromises = scrapedArticles.map(async (article) => {
        if (article.error || !article.content) {
          return null
        }

        const portalName = new URL(article.url).hostname.replace('www.', '')

        // Generate informal explanation with AI
        logger.info(`ü§ñ Explaining: ${article.title.substring(0, 50)}...`)
        const explained = await explainArticle(article.title, article.content)

        return {
          title: article.title,
          url: article.url,
          content: article.content,
          portal: portalName,
          explained: explained || 'Explicaci√≥n no disponible ü§∑',
        }
      })

      const results = await Promise.all(explanationPromises)
      fullArticles.push(...results.filter((article) => article !== null))

      logger.info(
        `‚úÖ Fetched and explained ${fullArticles.length}/${selectedUrls.length} articles`
      )
    }

    // Save to cache with full articles
    await NewsCache.create({
      summary,
      articles: fullArticles, // Full articles, not the original 160
      rawContent: combinedContent.substring(0, 50000), // Keep for backward compatibility
    })

    // Clean old cache (keep only the last 10)
    const allCache = await NewsCache.find().sort({ createdAt: -1 }).skip(10)

    if (allCache.length > 0) {
      await NewsCache.deleteMany({
        _id: { $in: allCache.map((c) => c._id) },
      })
      logger.info(`üóëÔ∏è Cleaned ${allCache.length} old cache entries`)
    }

    logger.info('‚úÖ News cache refreshed successfully')
    return summary
  } catch (error) {
    logger.error('Error refreshing summary:', error)

    // Devolver √∫ltimo cache como fallback
    const lastCache = await NewsCache.findOne().sort({ createdAt: -1 })

    if (lastCache) {
      logger.info('‚ö†Ô∏è Returning last cached summary due to error')
      return lastCache.summary
    }

    throw new Error('No se pudo refrescar el resumen de noticias')
  }
}
